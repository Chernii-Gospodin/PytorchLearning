# Задание 1: Сравнение CNN и полносвязных сетей (40 баллов)
## 1.1 Сравнение на MNIST (20 баллов)

---
Сравните производительность на MNIST:
>
- Полносвязная сеть (3-4 слоя)
- Простая CNN (2-3 conv слоя)
- CNN с Residual Block


Для начала я скопировал с гитхаба код на обучение моделей *(run_epoch, train_model, Dataset|Dataloader)*, и взял основы классов простых нейронных сетей (после чуть видоизменил и добавил свой класс Linear), а после обучил модели

Для каждого варианта:
>
- Обучите модель с одинаковыми гиперпараметрами
>>Обучил
>
- Сравните точность на train и test множествах
>>Скопировал функции plot_training_history, визуализировал метрики, самой точной оказалась CNN ~0.993+ test accr, далее ResNet, а FCN начала переобучаться после 7 итерации (видно, что tesst accr начал падать)![alt text](https://picsum.photos/400)
>
- Измерьте время обучения и инференса
>> Вывел время инференс - самая быстрой оказалась CNN модель, после FCN, и самая медленная ResNet
>
- Визуализируйте кривые обучения
>> Визуализировал с помощью AUC-ROC и везде мне показывались метрики   > 0.99+, что удивило меня ![alt text](https://picsum.photos/400)
>
- Проанализируйте количество параметров
>> Получил интересные данные: самая лучшая модель - CNN, и там 50186 параметров. Дальше идет ResNet - 163466, после FC - 70090. То есть CNN оказалась легче и гибче


---

## 1.2 Сравнение на CIFAR-10 (MNIST) (20 баллов)
 Сравните производительность на CIFAR-10 *(к сожалению, **без Cifar10**, так как у меня не грузит ни putorch, ни файл с сайта. Даже с VPN)*:
 
 >
- Полносвязная сеть (глубокая)
>> Создал с 5-ю Linear(out => 1024, 512, 512, 256, num_classes).
>> Структура: Linear -> ReLU -> Dropout(0.5/0.3/0/25), *3* раза подряд
>
- CNN с Residual блоками
>> Создал с 3-мя блоками
>
- CNN с регуляризацией и Residual блоками
 
 Для каждого варианта:
 >
 - Обучите модель с одинаковыми гиперпараметрами
>> Обучил
>
 - Сравните точность и время обучения
 >> Сохранил и визуализировал метрики. У DeepFCN график потерь и accuracy гладкий, но вот что удивило - Test accr (~0.98+)  больше Train accr. У ResNetCNN график получился очень ломанный (скорее всего из-за отсутствия + обучался *ОЧЕНЬ* долго (37 минут 10 эпох), но результыт вполне сносный - в пике test accr 0.99+, что очень радует.![alt text](https://picsum.photos/400)
 >
 - Проанализируйте переобучение
 >> Переобучения не заметил (скорее всего из-за недостатка эпох), но   до него будет тяжело дойти из-за огромного кол-ва параметров
 > 
 - Визуализируйте confusion matrix
>> График![alt text](https://picsum.photos/400)
> 
 - Исследуйте градиенты (gradient flow)
>> График![alt text](https://picsum.photos/400)



#### В этой работе я понял, что CNN - универсальный элемент нейронной сети, обладает гибкостью, мощностью и легкостью. Мега машина в мире нейронных сетей, применяется практически везде (Faster R-CNN, ResNet50 + R-CNN). Также отточил навык считывания и понимания метрик и их графиков. Повторил, как создавать каркас для NN-сетей 





