# Дз №3 выполнил вовремя в срок, перенес в отдельную папку и создал REPORT.md для удобства 

# Задание 1: Эксперименты с глубиной сети (30 баллов)
## 1.1 Сравнение моделей разной глубины (15 баллов)
Создайте и обучите модели с различным количеством слоев:
 - 1 слой (линейный классификатор)
 - 2 слоя (1 скрытый)
 - 3 слоя (2 скрытых)
 - 5 слоев (4 скрытых)
 - 7 слоев (6 скрытых)

 
Для каждого варианта:
- Сравните точность на train и test
>
>![alt text](https://github.com/Chernii-Gospodin/PytorchLearning/blob/main/Homework%203/plots/FC_layers_metrics.png)
> 
> Точность на test всегда немного ниже, чем на train. Связано это с тем, что модель "запоминает" значения из train выборки.
- Визуализируйте кривые обучения
> Заметил, что графики на тестовых выборках более ломанные, чем на тренировочной. Опять же это проявление "запоминания" значений признаков 
- Проанализируйте время обучения
> Чем больше слоев, тем больше параметров, которые нужно изменить. Отсюда скорость обучения снижается

## 1.2 Анализ переобучения (15 баллов)
- Проанализируйте, когда начинается переобучение
> У модели с 5 слоями не очень видно, но график после 40 эпох **test_losses** начинает немного подниматься вверх, что говорит о начале переобучении
>
>  ![alt text](https://github.com/Chernii-Gospodin/PytorchLearning/blob/main/Homework%203/plots/over_training.png)
> 
- Добавьте Dropout и BatchNorm, сравните результаты
> У модели с dropout and BatchNorm график остается таким же, но скорость наростания уже примерно меньше в **2 раза**
>
>![alt text](https://github.com/Chernii-Gospodin/PytorchLearning/blob/main/Homework%203/plots/over_training_with_dropout_normbatch.png)
> 
 - Определите оптимальную глубину для каждого датасета
> Для обычной с 5 слоями - около 30, с Dropout/BatchNorm - около 40, но можно также оставить 30

---

# Задание 2: Эксперименты с шириной сети (25 баллов)
## 2.1 Сравнение моделей разной ширины (15 баллов)
 Создайте модели с различной шириной слоев:
 - Узкие слои: [64, 32, 16]
 - Средние слои: [256, 128, 64]
 - Широкие слои: [1024, 512, 256]
 - Очень широкие слои: [2048, 1024, 512]
 
 Для каждого варианта:
 - Поддерживайте одинаковую глубину (3 слоя)
 - Сравните точность и время обучения
> ![alt text](https://github.com/Chernii-Gospodin/PytorchLearning/blob/main/Homework%203/plots/FC_deiiferent_wide_metrics.png)
> 
 - Проанализируйте количество параметров
>Model slim layer: 52650 parametrs. Time: 153.46 sec\
Model medium layer: 235146 parametrs. Time: 165.79 sec\
Model wide layer: 1333770 parametrs. Time: 202.96 sec\
Model huge layer: 3716106 parametrs. Time: 182.58 sec\
Здесь самая оптимальная **medium сеть**: всего 235146 параметров и достаточна стабильна.\
Losses/Accuracy примерно такое же, как и у *Wide, Huge моделей*


## 2.2 Оптимизация архитектуры (10 баллов)
Найдите оптимальную архитектуру:
- Используйте grid search для поиска лучшей комбинации
- Попробуйте различные схемы изменения ширины (расширение, сужение, постоянная)
- Визуализируйте результаты в виде heatmap


# Задание 3: Эксперименты с регуляризацией (25 баллов)
## 3.1 Сравнение техник регуляризации (15 баллов)
Исследуйте различные техники регуляризации:
- Без регуляризации
- Только Dropout (разные коэффициенты: 0.1, 0.3, 0.5)
 - Только BatchNorm
 - Dropout + BatchNorm
 - L2 регуляризация (weight decay)
 
 Для каждого варианта:
 - Используйте одинаковую архитектуру
 - Сравните финальную точность
 > ![alt text](https://github.com/Chernii-Gospodin/PytorchLearning/blob/main/Homework%203/plots/FC_dropout_batchnorm_metrics.png)
- Проанализируйте стабильность обучения
> Как мы видим, самые низкие потери и высокие значения на тренировочных данных (причем ведет себя очень стабильно( - usual layer. Она же дает самые высокие потери и низкую точность относительно других моделей на тестовой ввыборке (вела себя нестабильно)
> 
> Dropout дает высокие и нестабильные потери, но стабильную точность
> 
> Самыми лучшими и стабильными относительно других на тестовой выборке были **Dropout + BatchNorm** и обычный **BatchNorm**. **Dropout + BatchNorm** был самым худшим по потерям и accuracy на train выборке, но вырвался вперед на test выборке, показав практически ***такой же результат***, как и на train выборке

 - Визуализируйте распределение весов




